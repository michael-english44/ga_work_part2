{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Predicting shots made per game by Kobe Bryant\n",
    "\n",
    "_Authors: Kiefer Katovich (SF)_\n",
    "\n",
    "---\n",
    "\n",
    "In this lab you'll be using regularized regression penalties Ridge, Lasso, and Elastic Net to try and predict how many shots Kobe Bryant made per game in his career.\n",
    "\n",
    "The Kobe shots dataset has hundreds of columns representing different characteristics of each basketball game. Fitting an ordinary linear regression using every predictor would dramatically overfit the model considering the limited number of observations (games) we have available. Furthermore, many of the predictors have significant multicollinearity. \n",
    "\n",
    "**Warning:** Some of these calculations are computationally expensive and may take a while to execute.  It may be worth while to only use a portion of the data to perform these calculations, especially if you have experienced kernel issues in the past.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Load packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import patsy\n",
    "\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet, LinearRegression, RidgeCV, LassoCV, ElasticNetCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "kobe = pd.read_csv('../data/kobe_superwide_games.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2. Examine the data\n",
    "\n",
    "- How many columns are there?\n",
    "- Examine what the observations (rows) and columns represent.\n",
    "- Why is this data that regularization might be particularly useful for?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'SHOTS_MADE', u'AWAY_GAME', u'SEASON_OPPONENT:atl:1996-97',\n",
       "       u'SEASON_OPPONENT:atl:1997-98', u'SEASON_OPPONENT:atl:1999-00',\n",
       "       u'SEASON_OPPONENT:atl:2000-01', u'SEASON_OPPONENT:atl:2001-02',\n",
       "       u'SEASON_OPPONENT:atl:2002-03', u'SEASON_OPPONENT:atl:2003-04',\n",
       "       u'SEASON_OPPONENT:atl:2004-05',\n",
       "       ...\n",
       "       u'ACTION_TYPE:tip_layup_shot', u'ACTION_TYPE:tip_shot',\n",
       "       u'ACTION_TYPE:turnaround_bank_shot',\n",
       "       u'ACTION_TYPE:turnaround_fadeaway_bank_jump_shot',\n",
       "       u'ACTION_TYPE:turnaround_fadeaway_shot',\n",
       "       u'ACTION_TYPE:turnaround_finger_roll_shot',\n",
       "       u'ACTION_TYPE:turnaround_hook_shot',\n",
       "       u'ACTION_TYPE:turnaround_jump_shot', u'SEASON_GAME_NUMBER',\n",
       "       u'CAREER_GAME_NUMBER'],\n",
       "      dtype='object', length=645)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kobe.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3. Make predictor and target variables. Standardize the predictors.\n",
    "\n",
    "Why is normalization necessary for regularized regressions?\n",
    "\n",
    "Use the `sklearn.preprocessing` class `StandardScaler` to standardize the predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.preprocessing\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "kobe_scaler = ss_scaler.fit_transform(kobe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ss_scaler.fit_transform creates an array of scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.12064946, -1.00128452, -0.03585174, ..., -0.64321838,\n",
       "        -1.61086697, -1.73304411],\n",
       "       [-2.12064946,  0.99871713, -0.03585174, ..., -0.64321838,\n",
       "        -1.57246428, -1.73082079],\n",
       "       [-1.54429152,  0.99871713, -0.03585174, ..., -0.64321838,\n",
       "        -1.53406159, -1.72859748],\n",
       "       ...,\n",
       "       [ 0.47296124,  0.99871713, -0.03585174, ...,  0.2771723 ,\n",
       "         0.80850225,  1.7264341 ],\n",
       "       [-1.25611256,  0.99871713, -0.03585174, ..., -0.64321838,\n",
       "         0.84690493,  1.72865741],\n",
       "       [ 3.35475091, -1.00128452, -0.03585174, ...,  0.16672542,\n",
       "         0.88530762,  1.73088073]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kobe_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4. Build a linear regression predicting `SHOTS_MADE` from the rest of the columns.\n",
    "\n",
    "Cross-validate the $R^2$ of an ordinary linear regression model with 10 cross-validation folds.\n",
    "\n",
    "How does it perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 5. Find an optimal value for Ridge regression alpha using `RidgeCV`.\n",
    "\n",
    "[Go to the documentation and read how RidgeCV works.](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html)\n",
    "\n",
    "> *Hint: once the RidgeCV is fit, the attribute `.alpha_` contains the best alpha parameter it found through cross-validation.*\n",
    "\n",
    "Recall that Ridge performs best searching alphas through logarithmic space (`np.logspace`). This may take awhile to fit!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 6. Cross-validate the Ridge regression $R^2$ with the optimal alpha.\n",
    "\n",
    "Is it better than the Linear regression? If so, why might this be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 7. Find an optimal value for Lasso regression alpha using `LassoCV`.\n",
    "\n",
    "[Go to the documentation and read how LassoCV works.](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html) It is very similar to `RidgeCV`.\n",
    "\n",
    "> *Hint: again, once the `LassoCV` is fit, the attribute `.alpha_` contains the best alpha parameter it found through cross-validation.*\n",
    "\n",
    "Recall that Lasso, unlike Ridge, performs best searching for alpha through linear space (`np.linspace`). However, you can actually let the LassoCV decide itself what alphas to use by instead setting the keyword argument `n_alphas=` to however many alphas you want it to search over. It is recommended to let sklearn choose the range of alphas.\n",
    "\n",
    "_**Tip:** If you find your CV taking a long time and you're not sure if its working set `verbose =1`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 8. Cross-validate the Lasso $R^2$ with the optimal alpha.\n",
    "\n",
    "Is it better than the Linear regression? Is it better than Ridge? What do the differences in results imply about the issues with the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 9. Look at the coefficients for variables in the Lasso.\n",
    "\n",
    "1. Show the coefficient for variables, ordered from largest to smallest coefficient by absolute value.\n",
    "2. What percent of the variables in the original dataset are \"zeroed-out\" by the lasso?\n",
    "3. What are the most important predictors for how many shots Kobe made in a game?\n",
    "\n",
    "> **Note:** if you only fit the Lasso within `cross_val_score`, you will have to refit it outside of that\n",
    "function to pull out the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 10. Find an optimal value for Elastic Net regression alpha using `ElasticNetCV`.\n",
    "\n",
    "[Go to the documentation and read how LassoCV works.](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNetCV.html).\n",
    "\n",
    "Note here that you will be optimizing both the alpha parameter and the l1_ratio:\n",
    "- `alpha`: strength of regularization\n",
    "- `l1_ratio`: amount of ridge vs. lasso (0 = all ridge, 1 = all lasso)\n",
    "    \n",
    "Do not include 0 in the search for `l1_ratio`: it will not allow it and break!\n",
    "\n",
    "You can use `n_alphas` for the alpha parameters instead of setting your own values: highly recommended!\n",
    "\n",
    "Also - be careful setting too many l1_ratios over cross-validation folds in your search. It can take a very long time if you choose too many combinations and for the most part there are diminishing returns in this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 11. Cross-validate the ElasticNet $R^2$ with the optimal alpha and l1_ratio.\n",
    "\n",
    "How does it compare to the Ridge and Lasso regularized regressions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 12. [Bonus] Compare the residuals for the Ridge and Lasso visually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A: Maybe a jointplot?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
